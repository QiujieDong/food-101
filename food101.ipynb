{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The classification of Food-101\n",
    "Transfer Learningï¼šResNet-50\n",
    "\n",
    "env: python3.6,tensorflow == 1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import GlobalAveragePooling2D, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/gpu/Project/food-101/food-101/images/'\n",
    "\n",
    "rows = 5\n",
    "cols = 6\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(15, 25))\n",
    "fig.suptitle('Randomly select pictures', fontsize=20) # create figure title\n",
    "sorted_food_dirs = sorted(os.listdir(root_dir))  # sort from low to high\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        try:\n",
    "            food_dir = sorted_food_dirs[i * cols + j]\n",
    "        except:\n",
    "            break\n",
    "        all_files = os.listdir(os.path.join(root_dir, food_dir))\n",
    "        rand_img = np.random.choice(all_files)\n",
    "        img = plt.imread(os.path.join(root_dir, food_dir, rand_img))\n",
    "        ax[i][j].imshow(img)\n",
    "        \n",
    "        # create sub-figure title\n",
    "        ec = (0, 0.6, 0.1) # the color of the border line\n",
    "        fc = (0, 0.7, 0.2) # the color of the background \n",
    "        ax[i][j].text(0, -20, food_dir, size=10, rotation=0, ha='left', va='top', bbox=dict(boxstyle='round', ec=ec, fc=fc))\n",
    "        \n",
    "plt.setp(ax, xticks=[], yticks=[]) # set a properyty of ax\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # automatically adjust sub-figure parameters to fill the entire image area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocessing.Pool is used to accelerate image augmentation during training\n",
    "import multiprocessing as mp\n",
    "\n",
    "num_processes = 6\n",
    "process_pool = mp.Pool(processes=num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function is used to split the dataset into a training set and a test set when the dataset hasn't split already.\n",
    "from collections import defaultdict  # There is a default value for each key in the dictionary.\n",
    "import shutil # High-level file operations\n",
    "\n",
    "if not os.path.isdir('./food-101/test') and not os.path.isdir('./food-101/train'):\n",
    "\n",
    "    def copytree(src, dst, symlinks = False, ignore = None):\n",
    "        if not os.path.exists(dst):\n",
    "            os.makedirs(dst)\n",
    "            shutil.copystat(src, dst)# only copy the status information of src to dst\n",
    "        lst = os.listdir(src)\n",
    "        if ignore:\n",
    "            excl = ignore(src, lst)\n",
    "            lst = [x for x in lst if x not in excl]\n",
    "        for item in lst:\n",
    "            s = os.path.join(src, item)\n",
    "            d = os.path.join(dst, item)\n",
    "            if symlinks and os.path.islink(s):\n",
    "                if os.path.lexists(d):\n",
    "                    os.remove(d)\n",
    "                os.symlink(os.readlink(s), d)\n",
    "                try:\n",
    "                    st = os.lstat(s)\n",
    "                    mode = stat.S_IMODE(st.st_mode)\n",
    "                    os.lchmod(d, mode)\n",
    "                except:\n",
    "                    pass # lchmod not available\n",
    "            elif os.path.isdir(s):\n",
    "                copytree(s, d, symlinks, ignore)\n",
    "            else:\n",
    "                shutil.copy2(s, d)\n",
    "\n",
    "    def generate_dir_file_map(path):\n",
    "        dir_files = defaultdict(list)\n",
    "        with open(path, 'r') as txt:\n",
    "            files = [l.strip() for l in txt.readlines()]\n",
    "            for f in files:\n",
    "                dir_name, id = f.split('/')\n",
    "                dir_files[dir_name].append(id + '.jpg')\n",
    "        return dir_files\n",
    "\n",
    "    train_dir_files = generate_dir_file_map('./food-101/meta/train.txt')\n",
    "    test_dir_files = generate_dir_file_map('./food-101/meta/test.txt')\n",
    "\n",
    "\n",
    "    def ignore_train(d, filenames):\n",
    "        print(d)\n",
    "        subdir = d.split('/')[-1]\n",
    "        to_ignore = train_dir_files[subdir]\n",
    "        return to_ignore\n",
    "\n",
    "    def ignore_test(d, filenames):\n",
    "        print(d)\n",
    "        subdir = d.split('/')[-1]\n",
    "        to_ignore = test_dir_files[subdir]\n",
    "        return to_ignore\n",
    "\n",
    "    copytree('./food-101/images', './food-101/test', ignore=ignore_train)\n",
    "    copytree('./food-101/images', './food-101/train', ignore=ignore_test)\n",
    "    \n",
    "else:\n",
    "    print('Train/Test files already copied into separate folders.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_generator(train_path, test_path, batch_size, dimentions):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  # this is the target directory\n",
    "        target_size=dimentions,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        test_path, # this is the target directory\n",
    "        target_size=dimentions,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "def load_image(img_path, dimentions, rescale=1. / 255):\n",
    "    img = load_img(img_path, target_size=dimentions)\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x *= rescale # rescale the same as when trained\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get classes label\n",
    "def get_classes(file_path):\n",
    "    with open(file_path) as f:\n",
    "        classes = f.read().splitlines()\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat model\n",
    "def create_model(num_classes, dropout, shape):\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_tensor=Input(\n",
    "            shape=shape))\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model_final = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "def train_model(model_final, train_generator, validation_generator, callbacks, args):\n",
    "    model_final.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    model_final.fit_generator(train_generator, validation_data=validation_generator,\n",
    "                              epochs=args.epochs, callbacks=callbacks,\n",
    "                              steps_per_epoch=train_generator.samples//args.batch_size,\n",
    "                              validation_steps=validation_generator.samples//args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "def load_model(weights_path, shape):\n",
    "    model_final = create_model(101, 0, shape)\n",
    "    model_final.load_weights(weights_path)\n",
    "\n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "\n",
    "args = argparse.ArgumentParser(description='Food 101 Program')\n",
    "args.batch_size = 32\n",
    "args.epochs = 1\n",
    "args.dropout = 0.2\n",
    "\n",
    "shape = (224, 224, 3)\n",
    "\n",
    "\n",
    "X_train, X_test = setup_generator('./food-101/train', './food-101/test', args.batch_size, shape[:2])\n",
    "\n",
    "# debug purposes\n",
    "print(X_train)\n",
    "\n",
    "# call backs have to be array\n",
    "callbacks = []\n",
    "\n",
    "# add a callback\n",
    "if not os.path.isdir('./saved_models_food101'):\n",
    "    os.mkdir('./saved_models_food101')\n",
    "callbacks.append(ModelCheckpoint(filepath='./saved_models_food101/weights.epoch-{epoch:02d}-val_loss-{val_loss:.2f}.hdf5',\n",
    "                               verbose=1, save_best_only=True))\n",
    "\n",
    "model_final = create_model(X_train.num_classes, args.dropout, shape)\n",
    "\n",
    "train_model(model_final, X_train, X_test, callbacks, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "args.model_path = './saved_models_food101/weights.epoch-17-val_loss-1.06.hdf5'\n",
    "args.image_path = './food-101/new_picture/1.jpg'\n",
    "\n",
    "trained_model = load_model(args.model_path, shape)\n",
    "image = load_image(args.image_path, shape[:2])\n",
    "preds = trained_model.predict(image)\n",
    "classes = get_classes('./food-101/meta/classes.txt')\n",
    "print(\"The image is: {} - {:.2f}%\".format(classes[np.argmax(preds)], max(preds[0, :]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the trained_model to current path\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(trained_model, to_file='trained_model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# visualization the trained_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(trained_model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization the trained_model parameters\n",
    "from keras.utils import print_summary\n",
    "print_summary(trained_model, line_length=None, positions=None, print_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert Keras model to Tensorflow model\n",
    "convert Keras's hdf5 to tensorflow's pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import os.path as osp\n",
    "from keras import backend as K\n",
    "\n",
    "#file path\n",
    "weight_file_path = osp.join(args.model_path)\n",
    "output_graph_name =  'TF.pb' \n",
    "\n",
    "#convert function\n",
    "def hdf5_to_pb(h5_model,output_dir,model_name,out_prefix = \"output_\",log_tensorboard = True):\n",
    "    if osp.exists(output_dir) == False:\n",
    "        os.mkdir(output_dir)\n",
    "    out_nodes = []\n",
    "    for i in range(len(h5_model.outputs)):\n",
    "        out_nodes.append(out_prefix + str(i + 1))\n",
    "        tf.identity(h5_model.output[i],out_prefix + str(i + 1))\n",
    "    sess = K.get_session()\n",
    "    from tensorflow.python.framework import graph_util,graph_io\n",
    "    init_graph = sess.graph.as_graph_def()\n",
    "    main_graph = graph_util.convert_variables_to_constants(sess,init_graph,out_nodes)\n",
    "    graph_io.write_graph(main_graph,output_dir,name = model_name,as_text = False)\n",
    "    if log_tensorboard:\n",
    "        from tensorflow.python.tools import import_pb_to_tensorboard\n",
    "        import_pb_to_tensorboard.import_to_tensorboard(osp.join(output_dir,model_name),output_dir)\n",
    "\n",
    "#output path\n",
    "output_dir = osp.join(os.getcwd(),\"tensorflow_model\")\n",
    "\n",
    "#load Keras(hdf5) model\n",
    "h5_model = load_model(weight_file_path)\n",
    "\n",
    "#convert keras(hdf5) to tensorflow(pb) model\n",
    "hdf5_to_pb(h5_model,output_dir = output_dir,model_name = output_graph_name)\n",
    "print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using tensorboard to visualization\n",
    "\n",
    "!tensorboard --logdir=./ tensorflow_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
